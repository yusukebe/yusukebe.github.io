{
    "data" :  {
    "title": "データ加工機としての Google BigQuery",
    "date": "2014-12-30 01:21:00 +0900 JST",
    "dir": "posts/2014/",
    "slug": "1230012100",
    "categories": ["tech"],
    "tags": []
}

---



<p><a href="http://bokete.jp/">ボケて</a>では既に「お題」が110万レコード、「ボケ」が2,300万レコード、それに対するユーザーの「評価」が1億1,000万レコード数存在します。このところそれをちょいと利用して、楽しいことをしましょうっていうんで、直近1年間の範囲である条件下のデータをエキスポートする必要がありました。ボケての基本的なデータは全て Amazon RDS の <strong>MySQL</strong> ストレージに格納されていて、この件で出力する形式は <strong>CSV</strong> フォーマットです。この場合、一般ユーザーがボケてのWebやモバイルアプリを操作する際に発生するクエリーとはまたひと味違った「<strong>重たい</strong>」クエリーを投げないとデータの「<strong>加工</strong>」が難しそうです。そんな際。<strong>Google BigQuery</strong> が非常に役に立ったので「<em>大雑把に</em>」その工程を紹介します。</p>




<p><img src="http://33.media.tumblr.com/d0ce15c715df0b3d49140f6f2b5c4ab4/tumblr_inline_nhdezh8EjK1qb2ehr.png" alt="BigQuery"></p>




<h3>投げては返ってこないMySQLへのクエリー</h3>




<p>今回は最終的に以下の3つの種類のデータをCSVで書きだすことになりました。取得範囲は2013年12月から1年間とします。</p>




<ul>
<li>評価に関すること</li>
<li>ボケに関すること</li>
<li>ユーザーに関すること</li>
</ul>


<p>例えば「評価」が <code>rating</code> というテーブルで表せられるならば以下のようなクエリーを MySQL に投げれば今回の要件はある程度満たせます。</p>




<pre class="code">SELECT * FROM rating
WHERE rating.date &gt;= '2013-12-01 00:00:00' AND rating.date &lt; '2014-12-01 00:00:00'</pre>




<p>しかし、2番目の「ボケに関すること」として「<strong>評価された対象のボケを集め、評価点数順にソートする</strong>」ってな要望があると <code>JOIN</code> が発生して、かつソートコストが高くなります。下は安直に書いた「例えば」のSQLクエリーです。</p>




<pre class="code">SELECT boke.*,SUM(rating.rate) as rate_sum FROM boke,rating
WHERE boke.id = rating.boke_id
AND rating.date &gt;= '2013-12-01 00:00:00' AND rating.date &lt; '2014-12-01 00:00:00'
GROUP BY boke.id ORDER BY rate_sum DESC</pre>




<p>これがいわゆる「重たいクエリー」になって投げてはなかなか返ってこないことになります。また、数十分〜数時間待って返ってきたとしても希望する結果でなければ再度修正して、再び同じ時間立たなければ、それが正しいかを検証することが出来ません。もちろん並び替えはせずに評価値のスコアを持つテンポラリーなテーブルをつくりインデックスさせるなど、他に賢いやり方があるかもしれませんが、今回は「<strong>Google BigQueryに頼ってなるべく頭をひねらない</strong>」という趣旨なので割愛しました。</p>




<h3>MySQLデータを BigQuery にのせる</h3>




<p>さて今回の解決策は前述の通り、Google BigQuery を使うというもの。「一時的に何千台のマシンを使ってフルスキャンさせる」という「<em>強引な</em>」 Google ならではのやり方は今回のような「ある意味<em>強引な</em>」クエリーを試すには持ってこいです。</p>




<p>諸々諸事情を加味して、以下のような手順で希望する3つのデータ＝CSVファイルを得ることが出来ました。</p>




<ol>
<li>一時的にEC2のハイメモリインスタンスを立ち上げる</li>
<li>RDSから <code>mysqldump</code> を実行し手元にダンプファイルをつくる</li>
<li>上記インスタンス上のローカルに MySQL サーバを立てて、ダンプファイルをインポート</li>
<li>ソートや <code>JOIN</code> など<strong>コストのかかるクエリーは抜いて</strong>指定範囲内のデータをCSVで書き出し</li>
<li>Googleのコマンドラインツールから <strong>Google Cloud Storage</strong> へアップロード</li>
<li>スキーマファイルをつくり、CSVのデータを <strong>Google BigQuery</strong> のテーブルへインポート</li>
<li>MySQLでは待たないと返ってこなかったようなクエリーを投げる =&gt; <strong>10s ちょいくらいで結果が出る！</strong>
</li>
<li>結果を一旦別テーブルへ書き出す</li>
<li>そのテーブルデータを <strong>Google Cloud Storage</strong> に CSV 形式でエキスポート</li>
<li>URLをみんなで共有</li>
</ol>


<p>冒頭の1〜3はしばらく待ってれば終わるとして、その後の作業を的確にやれば、半日、いや1時間くらいで作業が終わった！</p>




<p><img src="http://33.media.tumblr.com/24d44f1b856e28d5bce898c57131b42f/tumblr_inline_nhdewe1jnj1qb2ehr.png" alt="BigQuery"></p>




<p>ここで改めて、Google BigQuery の凄さというか便利さを「個人的に」まとめると以下の通り。</p>




<ul>
<li>
<strong>しかたのない</strong>「重たいクエリー」をマシンパワーで高速に処理してくれる</li>
<li>
<code>Browser Tool</code> が充実していて、クエリーの実行から、結果の表示、履歴の保存まで用意されたWebインターフェースで出来る</li>
<li>
<code>Google Cloud Storage</code> 等とも連動して便利</li>
<li>今や誰もが持っているGoogleアカウントで権限を移譲可能</li>
<li>ストリームデータの取り込みもある</li>
<li>何よりも安い！ ( 今回のデータ加工は無料範囲内で収まった )</li>
</ul>


<hr>
<p>いや〜 今回のケースはデータの出力と加工だったので、「楽出来ることは楽して」サッサと終わらせたかったので非常に BigQuery が重宝しました。上記フローは初めて試したものだったので、ある程度半自動化していけば、より簡単になるかもしれませんね。現在は他にも、行動ログに近いものをストリームで BigQuery に流し込んでいるのですが、それだけではなく<strong>データ加工にも使えるよん♪</strong> というお話でした。ちゃんちゃん</p>



 
}
