<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on ゆーすけべー日記</title>
    <link>https://yusukebe.com/tags/aws/</link>
    <description>Recent content in AWS on ゆーすけべー日記</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>© Copyright yusukebe.com</copyright>
    <lastBuildDate>Wed, 02 Dec 2015 11:50:00 +0900</lastBuildDate>
    
	<atom:link href="https://yusukebe.com/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Amazon Auroraを東京リージョン提供翌日から使い始めて</title>
      <link>https://yusukebe.com/posts/2015/1202115041/</link>
      <pubDate>Wed, 02 Dec 2015 11:50:00 +0900</pubDate>
      
      <guid>https://yusukebe.com/posts/2015/1202115041/</guid>
      <description> 概要 とあるサービスでは、Amazon Web Servicesをベースにインフラを組んでいる。データベースにおいてはRDSのMySQLのストレージエンジンを利用していたが、Amazon Auroraへと移行をした。それはAuroraがTokyoリージョンでの提供を開始した翌日のことで、中々勇気がいることであったが、結果「無難」に動いてそこそこ満足という評価。元々MySQLの時分ではインスタンス自体がオーバースペック気味だったので、今回のAurora導入でインスタンスサイズと構成を見直し、全体のパフォーマンスがWeb APIサーバーの平均レスポンスタイムを見ると10ミリ秒以上遅くなってしまったが、ユーザー体験とアプリケーションの性質上コストの兼ね合いで割り切ることとした。という事情があり、MySQLとAuroraの比較が環境やコストの差で非常にしにくいが、いくつかの点で移行してよかったと感じる。詳細を以下に書きます。
パフォーマンス Amazon Auroraの公式ページでは「MySQLの5倍の性能」とあるが、これは「とある条件下」での最大計測値だと見た方が妥当という点で注意したい。まぁ、実際状況によってはそれほどパフォーマンスが出る場合もあるとのことです。
 
 RDSにおいて、Auroraではディスクサイズを予め明示してからインスタンスを用意しなくとも、自動的にスケールでしてくれて大変助かる。一方、MySQLストレージエンジンの場合は当然、ディスクサイズを「100GB」使うとかCapacity Palanningする。その代わり、であるが、MySQLストレージエンジンではディスクサイズを大きくすればするほどディスクへのI/OアクセスであるIOPSが上がる。今回の件ではこのIOPSを「かなり」あげていた。かつ、クエリーによってはディスクアクセスが発生するものが存在した（CPU性能も加担しているかもしれない）。なので、パフォーマンスが出ていた状態であった。一方Auroraの場合、IOPSのコントロールはしにくい。
対象となるサービスではOAuth2認証とJSONRPCを喋るいわゆる「Web API」なのだが、結果前述した通り、全エンドポイントの平均レスポンスタイムが10ミリ秒上がった。つまり遅くなったってことだが、同時に、インスタンスサイズを見直すいい機会になり、また、MySQLの時にIOPSを「かなり」あげて富豪的解決をしていたのに改めて気付かされた。よってパフォーマンスへの施策として、サボリ気味だった、いくつかのクエリーチューニングやインデックスの調整なども行った。結果、コスト削減の効果が実際出始めていて、特に利用者の多いモバイルアプリでのユーザービリティにも影響はほとんど出ていない。
使い勝手 Auroraではひとつのインスタンスが必ず2つの「Availability Zone」にまたがるということになっている。またMySQLでの「Master-Replica」という文言は使わずに「Writer-Reader」という言葉を使う。基本的にはMasterにあたるWriterとRead ReplicaにあたるReaderを用意すれば冗長化は済んでしまう。また、レプリケーションの処理をストレージエンジン部分ではなく、確か、ディスクシステムレイヤーでやっちゃう、みたいな仕組みなんで、マスターとレプリカとのラグといった概念はほとんど存在しない。というかラグは0と考えて良い。その都合も含め、この場合、Masterとして利用しているWriterがコケた場合に、ReaderがMasterへ昇格する際のフェイルオーバーが速いといった特徴がある。
 
 とはいえ、何よりも増え続けるデータのCapacity Planningという難しいことをせずとも、自動的にスケールしてくれるのが嬉しいところである。
導入 東京リージョンでの提供開始日の翌日に早速導入したわけだが、比較的すんなりいった。当然サービスはメンテ状態にしないといけないんだけれども、基本的にはMySQLのRDSからスナップショットをとり、そこから新たにAuroraを立ち上げる形になる。大きなテーブルでは2億ほどレコードがあるDBになるが、メンテ諸々の作業合わせて3時間ジャストくらいでイケた。Readerに関しては無停止でインスタンスを追加したり削除したり出来るので、一番負荷が高い「22時30分」頃のピーク時でのパフォーマンスをCloudWatch+Libratoで監視しつつサイズを合わせて行った。
同時にクエリーやインデックスのチューニングも後々行ったので「パフォーマンスが落ちた」とはいえ、最小限に留めるように努力出来る余地があった。
MySQLとの互換性 これはビックリするほど「MySQL 5.6」と互換性がある。例えば、懸念していた「Online DDL」も5.6相当のものだし「Percona Toolkit」のpt-online-schema-changeコマンドも問題無く動いた。これで「ある程度無停止」でスキーマを変更することが出来るので安心。
まとめ 正直「すっげーAuroraいいよ！」とは言えないが、MySQLとの互換性が今後保たれていくことが保証されるという前提で「特にAuroraじゃない理由はない」という具合でデフォルトで使う感じになる気がする。ポイントは
 スケーラブル MySQL互換（現状は5.6） 冗長性が高い  となるだろう。現段階ではAuroraとして導入出来るインスタンスタイプがdb.r3.largeからとミニマムスタートには少々お高い感じになっているので、状況によっては敷居が高いが、Amazonの気合が感じられるプロダクトであるので今後スタンダードになるというジャッジで使うのはアリだと思います。
 
Amazon Web Services実践入門 (WEB+DB PRESS plus)
  作者: 舘岡守,今井智明,永淵恭子,間瀬哲也,三浦悟,柳瀬任章  出版社/メーカー: 技術評論社  発売日: 2015/11/10  メディア: 単行本（ソフトカバー） この商品を含むブログを見る     </description>
    </item>
    
    <item>
      <title>ELB配下のEC2インスタンスにデプロイをする</title>
      <link>https://yusukebe.com/posts/2013/0520020744/</link>
      <pubDate>Mon, 20 May 2013 11:07:00 +0900</pubDate>
      
      <guid>https://yusukebe.com/posts/2013/0520020744/</guid>
      <description>Amazon Web Services＝AWSの話。実運用で使うかどうかは検討中なんだけど、とあるELBにぶら下がっているEC2インスタンスを自動的に取得して、それに対してデプロイ等を行うってのをPerlでやってみた。デプロイツールとしてCinnamonを使い、ELBやEC2情報を取得するのにAWS::CLIWrapperを利用した。
awscliのPerlラッパーであるAWS::CLIWrapperを使うにはそもそも「awscli」をインストールしなくてはいけないので入れる。
 % sudo eazy_install awscli  これでawsコマンドが使えるようになるんだけど、補完が効いた方がいいので、設定する。zshの場合はちょっと工夫が必要で以下のようにする。どのファイルを扱うかはお好きなように。
 % mkdir ~/.zsh &amp;amp;&amp;amp; cd ~/.zsh % wget &#34;https://raw.github.com/aws/aws-cli/develop/bin/aws_zsh_completer.sh&#34; % echo &#34;source ~/.zsh/aws_zsh_completer.sh&#34; &amp;gt;&amp;gt; ~/.zshrc % source ~/.zshrc  ターミナルで素早くコマンドを試したい時にはこのawsコマンドを使う。
さて、ここからが本題。デプロイ先はEC2のPublic DNS Nameを利用すると仮定し、そのリストをAWS::CLIWrapperを使って取得し、Cinammonに渡せばいい。流れは以下の通り。
 elb describe-load-balancers を実行してターゲットとするELBの情報を一覧で取得する ELBの情報には、それぞれ組み付いているEC2インスタンスのIDのみが入っている ecs describe-instances を実行してEC2の情報を一覧で取得する 一覧をループで回して先ほどのELBと関連しているEC2のIDと比較する マッチしたらそのPublic DNS Nameを配列リファレンスに入れる Cinnamonの「Lazily evaluated」機能を使ってそのホスト情報でデプロイさせる  動作可能性の高いコードは以下の通り。具体的な設定をしたら動きました。
 use AWS::CLIWrapper; use Cinnamon::DSL; use YAML; my $aws = AWS::CLIWrapper-&amp;gt;new(); role api =&amp;gt; sub { my $res = $aws-&amp;gt;elb(&#39;describe-load-balancers&#39;); die Dump $AWS::CLIWrapper::Error unless $res; my $elb; for my $r (@$res) { if ( $r-&amp;gt;{LoadBalancerName} eq &#39;myapp-test-elb&#39; ) { $elb = $r; } } die get(&#39;target_elb_name&#39;) . &#34; is not found.</description>
    </item>
    
    <item>
      <title>AWS運用。1ヶ月経ってからのTips箇条書き</title>
      <link>https://yusukebe.com/posts/2013/0313070953/</link>
      <pubDate>Wed, 13 Mar 2013 16:09:00 +0900</pubDate>
      
      <guid>https://yusukebe.com/posts/2013/0313070953/</guid>
      <description>今週末の金曜日、3月15日に「JAWS DAYS 2013」のパネルディスカッションのパネラーとして呼ばれておりましてー。 風呂グラマーのmasuidriveさんとTreasure Dataの太田さんとお話をするらしく多少ビビってる僕です。
 プログラム・スピーカー紹介 | JAWS DAYS 2013 | 2013/3/15（金）～16日（土）東京ビッグサイトで開催！  実はこのAmazon Web Serviceユーザーにおける祭典「JAWS DAYS」のイベントに呼ばれた前日。 ちょうどボケてを某さくらVPSからEC2含むAWSへせっせと移行していましてー。 ま、つまりは「AWSでこれからバリバリ運用始めるぜ！」ってタイミングでのお呼ばれでしたw
イベント自体はおもろい事話せればいいなーとは思いつつ、AWSへ移行して、もしくはAWSへの準備の段階で得たTipsを箇条書きでまとめてみます。ちなみに、その移行以前からS3とCloudFrontに限っては画像ストレージ、配信というユースケースで利用していました。その関係あってか、Amazonの営業と技術の方と数回の打ち合わせをしてからのー「ほぼ全リソースをAWSへ移行」となりました。使っているAWSサービスは以下となります。
 S3 CloudFront EC2 RDS ELB CloudWatch Route53 SES  では以下にパラパラとTips的なことを公開できる範囲で書いていきます。
 
 Sorry Pageは出せないけどLoad BalancerはELBに任せよう（追記: Sorry PageはRoute53と組み合わせると出来そうだってことが分かったばかりでやってない） Webサイト、Web APIなどサービスドメインごとにELBは分けた方がいい、耐障害性が上がる EC2それぞれにnginx＋Starman/Starlet（Perlのアプリケーションサーバ）という構成はアリ ELBがL4スイッチ、nginxがL7スイッチという感覚 転送量について、S3とCloudFrontの中間キャッシュという技があるが、当然CloudFrontとクライアント間における解決策ではない むしろクライアント側でキャッシュすべき CloudFrontには10TB/月の転送量を約束するReserved Capacityという割引制度がある Reserved Instanceに限らず、AWSには割引の制度が色々あるので使用料が大きい場合は相談した方がいいかも AMIはサーバミドルウェア、アプリ、レポジトリが入った状態で固めるのがオススメ Chefとか使えばそんなことないかも、だけど、俺は今の所AMIで管理している（デメリットもある） AutoScalingは無し、手動でやろう。そういうユーザも多い それぞれの操作はWebコンソールから。あえてコマンドを覚える必要はないと思う ec2ssh はホスト名コピペとかしなくていいからオススメ RDSではmysqlテーブルにslow query log相当の物が入ってる CloudWatchは2週間しかデータを保持しないから、他にも監視システムを入れるのをオススメされた 元々使ってるCloudForecast/GrowthForecastとか通知システムとかをそのまま利用 AMIはインスタンスサイズが違ってもOK、リージョンまたぐとダメ EC2はMedium使うよりSmallインスタンスをたくさん使った方がCPUリソースを使えるケースがある 性能表に書いてある「ECU」ってのは非常に性能の低いCPUと見なせる なのでm1.largeではなく、ハイCPUインスタンスのc1.mediumをメインで利用している EC2からメール送信すると諸々問題あるのでSES経由で配信。APIを叩くのではなくSMTPサーバとして利用 サポートに入ると全体の1割増し、電話24時間サポートが付く、困ったときに入ればよいかと Reserved Instanceは購入の瞬間にクレジットカード会社に請求が発生、通常に買い物をするのと同じ なんだかんだ言って、当初考えていた料金の1.5倍くらいに請求額がいってしまったので怖いw クレジットカードの限度額等の確認、なるべく法人で専用のカードが良い、クラウド破産に注意   
AWSを使っての全体的な感想としては、すんなりとインフラが揃ったって感じで、後はアプリのつくりとか運用のテクニック、つまり自分の腕次第だなーってものです。大昔といっても3年くらい前にEC2は触ってたのですが、エラい色んなサービスが出ててビックリしましたねー。AWSコンソールでほぼなんでも出来ちゃうのも便利です。
ってことで箇条書きでAWSにおける僕なりのTipsや伺った話をまとめてみました。興味のある方は3月15日（金）の「JAWS DAYS 2013」にお越し下され！</description>
    </item>
    
  </channel>
</rss>